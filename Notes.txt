Kubernetes in Docker (kind): https://github.com/kubernetes-sigs/kind is used in the continuos integration pipeline as a single node cluster for testing application. Easy start and stop. ephemeral clusters that start quickly and are in a pristine state for testing applications in Kubernetes each time you check in your code
There are two service discovery mechanisms built into Kubernetes:
  Environment variables - The environment variables follow a naming convention so that all you need to know is the name of the service to     access it. Kubernetes will automatically inject environment variables in containers that provide the address to access services.
  When using environment variables for service discovery the service must be created before the pod in order to use environment variables     for service discovery. The service must also be in the same namespace.
  DNS - Kubernetes also constructs DNS records based on the service name and containers are automatically configured to query the cluster’s   DNS to discover services. DNS records overcome the shortcomings of environment variables. DNS records are added and removed from the cluster’s DNS as services are created and deleted. The DNS name for services include the namespace allowing communication with services in other namespaces. SRV DNS records are created for service port information 
LOGS - kubectl logs -n service-discovery support-tier poller -f
kubectl rollout -n deployments pause deployment app-tier
kubectl rollout -n deployments resume deployment app-tier
Probes are sometimes referred to as health checks.
Readiness probe - They are used to probe when a pod is ready to serve traffic. As I mentioned before often a pod is not ready after its containers have just started. They may need time to warm caches or load configurations. Readiness probes can monitor the containers until they are ready to serve traffic. But readiness probes are also useful long after startup. For example, if the pod depends on an external service and that service goes down, it’s not worth sending traffic to the pod since it can’t complete it until the external service is back online. Readiness probes control the ready condition of a pod. If a readiness probe succeeds the ready condition is true, otherwise it is false. Services use the ready condition to determine if pods should be sent traffic. In this way probes integrate with services to ensure that traffic doesn’t flow to pods that aren’t ready for it.
liveness probe - They are used to detect when a pod has entered a broken state and can no longer serve traffic. In this case, Kubernetes will restart the pod for you. That is the key difference between the two types of probes. Readiness probes determine when a service can send traffic to a pod because it is temporarily not ready and liveness probes decide when a pod should be restarted because it won’t come back to life. You declare both probes in the same way, you just have to decide which course of action is appropriate if a probe fails: stop serving traffic or restart.
All of a pods containers probes must pass for the pod to pass
You can define any of the following as the action a probe performs to check the container:
    a command that runs inside the container - A command probe succeeds if the exit code of the command is 0, otherwise it fails.
    An HTTP GET request - An HTTP GET request probe succeeds if the response status code is between 200 and 399 inclusive.
    Or opening a TCP socket - A tcp socket probe succeeds if a connection can be established. 
By default the probes check the pods every 10 seconds.
Remember that probes kick in after containers are started. If you need to test or prepare things before the containers start, there is a way to do that as well. That is the role of init containers 
Sometimes you need to perform some tasks or check some prerequisites before a main application container starts. Some examples include waiting for a service to be created, downloading files the application depends on, or dynamically deciding which port the application should use.Pods may declare any number of init containers. They run in a sequence in the order they are declared. Each init container must run to completion before the following init container begins. Once all of the init containers have completed the main containers in the pod can start. Init containers use different images from the containers in a pod. This provides some benefits. They can contain utilities that are not desirable to include in the actual application image for security reasons. They can also contain utilities or custom code for setup that is not present in the application image. For example there is no need to include utilities like Sed Awk or dig in an application image if they are only used for setup. Init containers also provide an easy way to block or delay the startup of an application until some preconditions are met. They are similar to readiness probes in this sense but only run at pod startup and can perform other useful work.
There is one important thing to understand about init containers. They run every time a pod is created. This means they will run once for every replica in a deployment. If a pod restarts, say due to a failed liveness probe, the init containers would run again as part of the restart. Thus you have to assume that init containers run at least once. This usually means init containers should be idempotent; meaning running it more than once has no additional effect.
The one exception is initContainers do not support readiness probes because they must run to completion before the state of the pod can be considered ready. 
Kubernetes pods allow you to have multiple containers sharing the same network space and can also share storage between containers.
Three multi-container patterns, the sidecar, the ambassador, and the adapter.
Pods allow you to specify additional information such as restart policies and probes to check the health of containers
Pods also allow you to seamlessly deal with different types of underlying containers, for example, Docker and Rocket. 
The sidecar pattern uses a helper container to assist a primary container. Common examples include logging agents that collect logs and ship them to a central aggregation system. 
The ambassador pattern uses a container to proxy communication to and from a primary container. The primary container only needs to consider connecting to localhost, while the ambassador controls proxying the connections to different environments. This is because containers in the same pod share the same network space, and can communicate with each other over localhost. 
This pattern is commonly used to communicate with a database.
The adaptor pattern uses a container to present a standardized interface across multiple pods. For example, presenting an interface for accessing output in a standardized format for logs, across several applications. The adaptor pattern is the opposite of the ambassador pattern, in that the ambassador presents a simplified view to the primary container while the adaptor pattern presents a simplified view of the application to the outside world.The adaptor pattern is commonly used for normalizing application logs, or monitoring data, so they can easily be consumed by a shared aggregation system. The adaptor may communicate with the primary container using either a shared volume when dealing with files or over localhost. 
Network policy - Ingress and Egress . Apply policy in a name space on set of pods. We need  a network pluugin to make it work.
service roles
kubectl shortcuts - AUTO Complete, generate yaml file, explain. filter get by label and sort by command
Load kubectl shell completions for your current shell session: source <(kubectl completion bash)
kubectl explain Pod.spec | more
kubectl explain pod.spec.containers | more
kubectl get pod first-pod -o yaml | more
kubectl get pod -o wide
kubectl create/apply -f first-pod.yaml
kubectl delete pod first-pod
https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-phase
kubectl create namespace labels
# Set namespace as the default for the current context : kubectl config set-context $(kubectl config current-context) --namespace=labels
kubectl get option to display columns for both labels: kubectl get pods -L color,tier
Use the -l (or --selector) option to select all Pods with a color label: kubectl get pods -L color,tier -l color
Select all Pods that do not have a color label:kubectl get pods -L color,tier -l '!color'
Select all Pods that have the color red:kubectl get pods -L color,tier -l 'color=red'
Select all Pods that have the color red and are not in frontend tier: kubectl get pods -L color,tier -l 'color=red,tier!=frontend'
Select all Pods with green or blue color: kubectl get pods -L color,tier -l 'color in (blue,green)'
kubectl get pod -n labels -L color,tier -l 'color notin (blue,green)'
kubectl describe pod red-frontend | grep Annotations
Remove the Pod's annotation : kubectl annotate pod red-frontend Lab-
The annotate command can be used to add/remove/update annotations. You add a dash (-) after the annotation key to remove the annotation. You can do the same with the kubectl label command when you need to remove a label.
add annotation kubectl annotate pod red-frontend Lab=yes -n labels
update kubectl annotate pod red-frontend Lab=NO -n labels --overwrite
